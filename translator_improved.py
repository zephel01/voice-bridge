"""
ç¿»è¨³ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆæ”¹å–„ç‰ˆï¼‰
deep-translator ã‚’ä½¿ã£ã¦è¤‡æ•°è¨€èªé–“ã®ç¿»è¨³ã‚’è¡Œã†
å°‚é–€ç”¨èªè¾æ›¸ã‚µãƒãƒ¼ãƒˆä»˜ã + ãƒ‡ãƒãƒƒã‚°ï¼†ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½æ­è¼‰
"""

import time
import re
import json
from datetime import datetime
from pathlib import Path

try:
    from deep_translator import GoogleTranslator
except ImportError:
    raise ImportError("deep-translator ãŒå¿…è¦ã§ã™: pip install deep-translator")


class Translator:
    """Google Translate ã‚’ä½¿ã£ãŸè¤‡æ•°è¨€èªç¿»è¨³ + å°‚é–€ç”¨èªè¾æ›¸å¯¾å¿œ + ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½"""

    # ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹è¨€èªãƒšã‚¢
    SUPPORTED_LANGUAGE_PAIRS = {
        ("en", "ja"), ("ja", "en"),
        ("zh-CN", "ja"), ("ja", "zh-CN"),
        ("es", "ja"), ("ja", "es"),
        ("fr", "ja"), ("ja", "fr"),
        ("de", "ja"), ("ja", "de"),
        ("ko", "ja"), ("ja", "ko"),
    }

    # è¨€èªã‚³ãƒ¼ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆUIç”¨ï¼‰
    LANGUAGE_CODE_MAP = {
        "zh": "zh-CN",
    }

    LANGUAGE_NAMES = {
        "en": "English",
        "ja": "æ—¥æœ¬èª",
        "zh": "ä¸­å›½èª",
        "es": "ã‚¹ãƒšã‚¤ãƒ³èª",
        "fr": "ãƒ•ãƒ©ãƒ³ã‚¹èª",
        "de": "ãƒ‰ã‚¤ãƒ„èª",
        "ko": "éŸ“å›½èª",
    }

    # æ—¢çŸ¥ã®èª¤è¨³ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ–ãƒ­ãƒƒã‚¯ãƒªã‚¹ãƒˆï¼‰
    MISTRANSLATION_PATTERNS = {
        # å‹•ç”»ã®çµ‚äº†ãƒ»æ¬¡å›ãƒ•ãƒ¬ãƒ¼ã‚º
        r"(?:æ¬¡|æ¬¡å›|ã¾ãŸ)\s*(?:ã®\s*)?(?:ãƒ“ãƒ‡ã‚ª|å‹•ç”»|æ˜ åƒ|ãƒ¬ãƒƒã‚¹ãƒ³|å›)(?:ã§|ã§\s*)(?:ãŠä¼šã„ã—ã¾ã—ã‚‡ã†|ä¼šã„ã¾ã—ã‚‡ã†|ãŠç›®ã«ã‹ã‹ã‚Šã¾ã—ã‚‡ã†)",
        r"(?:æ¬¡\s*(?:ã®|ã®\s*))?(?:ãƒ“ãƒ‡ã‚ª|å‹•ç”»|æ˜ åƒ|ãƒ¬ãƒƒã‚¹ãƒ³)(?:ã§|ã§\s*)(?:ãŠä¼šã„ã—ã¾ã—ã‚‡ã†|ä¼šã„ã¾ã—ã‚‡ã†)",
        r"(?:ãã‚Œã§ã¯|ã§ã¯|ãã‚Œã§ã¯)|(?:æ¬¡\s*(?:ã¾ã§|ã¾ã§\s*)?|ã˜ã‚ƒã‚|ã§ã¯)\s*(?:ã¾ãŸ|ã¾ãŸã­|ã¾ãŸã‚ã—ãŸ|ã¾ãŸæ˜æ—¥|ã˜ã‚ƒã‚|ã§ã¯)",
        r"çµ‚ã‚ã‚Š|ãŠã‚ã‚Š|ã“ã®å‹•ç”»ã¯ã“ã“ã¾ã§",
        r"(?:ã“ã®ãƒ“ãƒ‡ã‚ª|ã“ã®å‹•ç”»|ã“ã“)ã§(?:çµ‚ã‚ã‚Š|çµ‚äº†|çµ‚ã‚ã‚Šã¾ã™)",
    }

    # è‹±èªã®æ—¢çŸ¥ã®èª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆWhisper ã‹ã‚‰ï¼‰
    WHISPER_MISTRANSLATIONS = {
        r"see you in the next video": True,  # ãƒ–ãƒ­ãƒƒã‚¯
        r"see you next time": True,          # ãƒ–ãƒ­ãƒƒã‚¯
        r"thanks for watching": True,        # ãƒ–ãƒ­ãƒƒã‚¯
        r"thanks for watching.*video": True, # ãƒ–ãƒ­ãƒƒã‚¯
        r"subscribe.*channel": True,         # ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ä¿ƒé€²ã¯èª¤èªè­˜ã—ã‚„ã™ã„ï¼‰
        r"like.*comment.*subscribe": True,   # ãƒ–ãƒ­ãƒƒã‚¯
    }

    def __init__(self, source: str = "en", target: str = "ja", max_retries: int = 3, debug: bool = False, log_file: str = None):
        """
        Args:
            source: ã‚½ãƒ¼ã‚¹è¨€èª (default: en)
            target: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èª (default: ja)
            max_retries: ç¿»è¨³å¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤å›æ•° (default: 3)
            debug: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ– (default: False)
            log_file: ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (default: None - ãƒ­ã‚°ç„¡åŠ¹)
        """
        # è¨€èªã‚³ãƒ¼ãƒ‰å¤‰æ›
        source = self.LANGUAGE_CODE_MAP.get(source, source)
        target = self.LANGUAGE_CODE_MAP.get(target, target)

        # è¨€èªãƒšã‚¢ã®æ¤œè¨¼
        if (source, target) not in self.SUPPORTED_LANGUAGE_PAIRS:
            raise ValueError(
                f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„è¨€èªãƒšã‚¢: {source}â†’{target}\n"
                f"å¯¾å¿œãƒšã‚¢: {self.SUPPORTED_LANGUAGE_PAIRS}"
            )

        self.source = source
        self.target = target
        self.max_retries = max_retries
        self.debug = debug
        self._translator = GoogleTranslator(source=source, target=target)

        source_name = self.LANGUAGE_NAMES.get(source, source)
        target_name = self.LANGUAGE_NAMES.get(target, target)
        print(f"[Translator] {source_name} ({source}) â†’ {target_name} ({target})")
        if self.debug:
            print(f"[Translator] ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: æœ‰åŠ¹")

        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
        self.log_file = log_file
        if self.log_file:
            Path(self.log_file).parent.mkdir(parents=True, exist_ok=True)
            print(f"[Translator] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {self.log_file}")

        # å°‚é–€ç”¨èªè¾æ›¸ï¼ˆåˆ†é‡åˆ¥ï¼‰
        self.terminology = {
            # ITãƒ»ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ç”¨èª
            "framework": "ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
            "database": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
            "API": "API",
            "machine learning": "æ©Ÿæ¢°å­¦ç¿’",
            "artificial intelligence": "äººå·¥çŸ¥èƒ½",
            "neural network": "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯",
            "algorithm": "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ",
            "data structure": "ãƒ‡ãƒ¼ã‚¿æ§‹é€ ",
            "cloud computing": "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°",
            "cybersecurity": "ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
            "blockchain": "ãƒ–ãƒ­ãƒƒã‚¯ãƒã‚§ãƒ¼ãƒ³",
            "cryptocurrency": "æš—å·è³‡ç”£",
            "web development": "ã‚¦ã‚§ãƒ–é–‹ç™º",
            "server": "ã‚µãƒ¼ãƒãƒ¼",
            "client": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ",

            # ãƒ“ã‚¸ãƒã‚¹ç”¨èª
            "stakeholder": "ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼",
            "revenue": "åç›Š",
            "profit margin": "åˆ©å¹…",
            "supply chain": "ã‚µãƒ—ãƒ©ã‚¤ãƒã‚§ãƒ¼ãƒ³",
            "ROI": "æŠ•è³‡å¯¾åŠ¹æœ",
            "KPI": "é‡è¦æ¥­ç¸¾è©•ä¾¡æŒ‡æ¨™",

            # ãã®ä»–ä¸€èˆ¬çš„ãªèª¤ã‚Šã‚„ã™ã„ç”¨èª
            "infrastructure": "ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ãƒ¼",
            "optimization": "æœ€é©åŒ–",
            "implementation": "å®Ÿè£…",
        }

    def _write_log(self, log_data: dict):
        """ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿"""
        if not self.log_file:
            return

        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_data, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"[Translator] ãƒ­ã‚°æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    def _should_block_whisper_mistranslation(self, text: str) -> bool:
        """Whisper ã®æ—¢çŸ¥èª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        text_lower = text.lower().strip()
        for pattern in self.WHISPER_MISTRANSLATIONS.keys():
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        return False

    def _should_block_ja_mistranslation(self, text: str) -> bool:
        """æ—¥æœ¬èªã®æ—¢çŸ¥èª¤è¨³ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        for pattern in self.MISTRANSLATION_PATTERNS:
            if re.search(pattern, text):
                return True
        return False

    def _apply_terminology(self, text: str) -> dict:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã«å¯¾ã—ã¦å°‚é–€ç”¨èªè¾æ›¸ã‚’é©ç”¨
        Returns:
            {
                "modified_text": è¾æ›¸èªã‚’<TERM_ID>ã§ç½®æ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ,
                "replacements": {"<TERM_ID>": "æ—¥æœ¬èª"}
            }
        """
        replacements = {}
        modified_text = text
        term_id = 0

        # ç”¨èªãƒãƒƒãƒãƒ³ã‚°ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’åŒºåˆ¥ã—ãªã„ï¼‰
        for en_term, ja_term in self.terminology.items():
            pattern = r'\b' + re.escape(en_term) + r'\b'
            if re.search(pattern, modified_text, re.IGNORECASE):
                placeholder = f"<TERM_{term_id}>"
                modified_text = re.sub(pattern, placeholder, modified_text, flags=re.IGNORECASE)
                replacements[placeholder] = ja_term
                term_id += 1

        return {
            "modified_text": modified_text,
            "replacements": replacements
        }

    def _restore_terminology(self, text: str, replacements: dict) -> str:
        """ç¿»è¨³å¾Œã€å°‚é–€ç”¨èªãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’æ—¥æœ¬èªã«å¾©å…ƒ"""
        result = text
        for placeholder, ja_term in replacements.items():
            result = result.replace(placeholder, ja_term)
        return result

    def _remove_duplicate_sentences(self, text: str) -> str:
        """
        é€£ç¶šã™ã‚‹é‡è¤‡ã—ãŸæ–‡ã‚’å‰Šé™¤
        ã‚ˆã‚Šè©³ç´°ãªåŒºåˆ‡ã‚Šæ–‡å­—ã«å¯¾å¿œï¼ˆå¥ç‚¹ã€ã‚²ãƒ«ã€æ„Ÿå˜†ç¬¦ï¼‰
        """
        # è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã«å¯¾å¿œ
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
        unique_sentences = []
        last_sentence = ""

        for sent in sentences:
            sent = sent.strip()
            if sent and sent != last_sentence:
                unique_sentences.append(sent)
                last_sentence = sent

        # åŒºåˆ‡ã‚Šæ–‡å­—ã®å¾©å…ƒï¼ˆç°¡æ˜“ç‰ˆï¼šå¥ç‚¹ã§çµ±ä¸€ï¼‰
        result = 'ã€‚'.join(unique_sentences)
        if text.endswith('ã€‚') or text.endswith('ï¼') or text.endswith('ï¼Ÿ'):
            result += 'ã€‚'
        return result

    def _merge_short_sentences(self, text: str) -> str:
        """
        çŸ­ã™ãã‚‹æ–‡ï¼ˆ5æ–‡å­—ä»¥ä¸‹ï¼‰ã‚’å‰ã®æ–‡ã¨çµåˆ
        ä¾‹: "ã¯ã˜ã‚ã«ã€‚ãƒ†ã‚¹ãƒˆã€‚" â†’ "ã¯ã˜ã‚ã«ãƒ†ã‚¹ãƒˆã€‚"
        """
        sentences = text.split('ã€‚')
        merged = []

        for i, sent in enumerate(sentences):
            sent = sent.strip()
            if not sent:
                continue

            # çŸ­ã„æ–‡ã¯å‰ã®æ–‡ã¨çµåˆ
            if merged and len(sent) <= 5:
                merged[-1] = merged[-1] + sent
            else:
                merged.append(sent)

        return 'ã€‚'.join(merged) + ('ã€‚' if text.endswith('ã€‚') else '')

    def add_terminology(self, term_dict: dict):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¿½åŠ ã®å°‚é–€ç”¨èªã‚’ç™»éŒ²ã™ã‚‹"""
        self.terminology.update(term_dict)
        print(f"[Translator] {len(term_dict)}å€‹ã®ç”¨èªã‚’è¿½åŠ ã—ã¾ã—ãŸ")

    def set_language_pair(self, source: str, target: str) -> bool:
        """è¨€èªãƒšã‚¢ã‚’å‹•çš„ã«å¤‰æ›´"""
        source = self.LANGUAGE_CODE_MAP.get(source, source)
        target = self.LANGUAGE_CODE_MAP.get(target, target)

        if (source, target) not in self.SUPPORTED_LANGUAGE_PAIRS:
            print(f"[Translator] ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„è¨€èªãƒšã‚¢: {source}â†’{target}")
            return False

        self.source = source
        self.target = target
        self._translator = GoogleTranslator(source=source, target=target)

        source_name = self.LANGUAGE_NAMES.get(source, source)
        target_name = self.LANGUAGE_NAMES.get(target, target)
        print(f"[Translator] è¨€èªãƒšã‚¢ã‚’å¤‰æ›´: {source_name} ({source}) â†’ {target_name} ({target})")
        return True

    def translate(self, text: str, skip_filter: bool = False) -> str:
        """
        ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã™ã‚‹ï¼ˆå°‚é–€ç”¨èªè¾æ›¸å¯¾å¿œ + èª¤è¨³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¯¾å¿œï¼‰

        Args:
            text: è‹±èªãƒ†ã‚­ã‚¹ãƒˆ
            skip_filter: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹ (default: False)

        Returns:
            æ—¥æœ¬èªã«ç¿»è¨³ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not text or not text.strip():
            return ""

        original_text = text.strip()

        # ã‚¹ãƒ†ãƒƒãƒ—1: Whisper ã®èª¤èªè­˜ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆè‹±èªã®å ´åˆï¼‰
        if self.source == "en" and self._should_block_whisper_mistranslation(original_text):
            log_data = {
                "timestamp": datetime.now().isoformat(),
                "stage": "whisper_filter",
                "original": original_text,
                "filtered": True,
                "reason": "æ—¢çŸ¥ã®èª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³"
            }
            self._write_log(log_data)
            if self.debug:
                print(f"[Translator] ğŸš« Whisper èª¤èªè­˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {original_text}")
            return ""

        # ã‚¹ãƒ†ãƒƒãƒ—2: å°‚é–€ç”¨èªã‚’æŠ½å‡ºãƒ»ç½®æ›
        term_data = self._apply_terminology(original_text)
        text_to_translate = term_data["modified_text"]
        replacements = term_data["replacements"]

        for attempt in range(self.max_retries):
            try:
                t_start = time.time()

                # ã‚¹ãƒ†ãƒƒãƒ—3: Googleç¿»è¨³ã‚’å®Ÿè¡Œ
                result = self._translator.translate(text_to_translate)
                t_translate = time.time() - t_start

                # ã‚¹ãƒ†ãƒƒãƒ—4: å°‚é–€ç”¨èªã‚’å¾©å…ƒ
                final_result = self._restore_terminology(result, replacements)

                # ã‚¹ãƒ†ãƒƒãƒ—5: æ—¥æœ¬èªã®èª¤è¨³ã‚’ãƒã‚§ãƒƒã‚¯
                if not skip_filter and self._should_block_ja_mistranslation(final_result):
                    log_data = {
                        "timestamp": datetime.now().isoformat(),
                        "stage": "ja_filter",
                        "original": original_text,
                        "translated": final_result,
                        "filtered": True,
                        "reason": "æ—¢çŸ¥ã®èª¤è¨³ãƒ‘ã‚¿ãƒ¼ãƒ³"
                    }
                    self._write_log(log_data)
                    if self.debug:
                        print(f"[Translator] ğŸš« æ—¥æœ¬èªèª¤è¨³ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {final_result}")
                    return ""

                # ã‚¹ãƒ†ãƒƒãƒ—6: é‡è¤‡ã—ãŸæ–‡ã‚’å‰Šé™¤
                cleaned_result = self._remove_duplicate_sentences(final_result)
                cleaned_result = self._merge_short_sentences(cleaned_result)

                # ãƒ­ã‚°å‡ºåŠ›
                log_data = {
                    "timestamp": datetime.now().isoformat(),
                    "stage": "success",
                    "original": original_text,
                    "translated": cleaned_result,
                    "duration_sec": t_translate,
                    "attempt": attempt + 1
                }
                self._write_log(log_data)

                if self.debug:
                    print(f"[Translator] âœ… ç¿»è¨³æˆåŠŸ ({t_translate:.2f}s): {original_text[:50]} â†’ {cleaned_result[:50]}")

                return cleaned_result if cleaned_result else ""

            except Exception as e:
                if attempt < self.max_retries - 1:
                    wait = 0.5 * (attempt + 1)
                    print(f"[Translator] ç¿»è¨³ã‚¨ãƒ©ãƒ¼ (ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{self.max_retries}): {e}")
                    time.sleep(wait)
                else:
                    print(f"[Translator] ç¿»è¨³å¤±æ•—: {e}")
                    log_data = {
                        "timestamp": datetime.now().isoformat(),
                        "stage": "error",
                        "original": original_text,
                        "error": str(e),
                        "attempt": attempt + 1
                    }
                    self._write_log(log_data)
                    return f"[ç¿»è¨³ã‚¨ãƒ©ãƒ¼] {text}"


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ1: åŸºæœ¬çš„ãªç¿»è¨³ï¼ˆãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹ï¼‰
    t = Translator(debug=True, log_file="/tmp/translator_debug.log")

    # ãƒ†ã‚¹ãƒˆ2: èª¤èªè­˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    result = t.translate("See you in the next video!")
    print(f"ãƒ†ã‚¹ãƒˆ2 çµæœ: '{result}' (ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚ŒãŸãŸã‚ç©ºæ–‡å­—)")

    # ãƒ†ã‚¹ãƒˆ3: æ­£å¸¸ãªç¿»è¨³
    result = t.translate("Hello, how are you today?")
    print(f"ãƒ†ã‚¹ãƒˆ3 çµæœ: {result}")

    # ãƒ†ã‚¹ãƒˆ4: å°‚é–€ç”¨èªã‚’å«ã‚€ç¿»è¨³
    result = t.translate("We use machine learning algorithms for cloud computing optimization.")
    print(f"ãƒ†ã‚¹ãƒˆ4 çµæœ: {result}")
